# ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê³„íšì„œ

## ğŸ¯ í…ŒìŠ¤íŠ¸ ëª©í‘œ

ë¸”ë™í”„ë¼ì´ë°ì´ ì‹œë‚˜ë¦¬ì˜¤(1ì´ˆ 1000ëª… ë™ì‹œ ì ‘ì†, 100ê°œ í•œì • íŒë§¤)ë¥¼ ì‹œë®¬ë ˆì´ì…˜í•˜ì—¬ ì‹œìŠ¤í…œì˜ ì„±ëŠ¥ í•œê³„ì™€ ë³‘ëª© ì§€ì ì„ íŒŒì•…í•©ë‹ˆë‹¤.

---

## ğŸ“Š ì£¼ìš” ì„±ëŠ¥ ì§€í‘œ (KPI)

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œê°’ | ì¸¡ì • ë°©ë²• |
|------|------|--------|-----------|
| **TPS** | ì´ˆë‹¹ ì²˜ë¦¬ íŠ¸ëœì­ì…˜ | v1: 100, v4: 1000+ | Locust/JMeter |
| **Response Time** | ì‘ë‹µ ì‹œê°„ | P50 < 100ms, P99 < 500ms | Percentile ë¶„ì„ |
| **Error Rate** | ì—ëŸ¬ ë°œìƒë¥  | < 0.1% | 4xx, 5xx ì‘ë‹µ ë¹„ìœ¨ |
| **Concurrency** | ë™ì‹œ ì‚¬ìš©ì ìˆ˜ | 1000ëª… | Active connections |
| **Lock Contention** | ë½ ê²½í•©ë¥  | < 30% | Redis ë©”íŠ¸ë¦­ |
| **Accuracy** | ì¬ê³  ì •í™•ë„ | 100% | ì‹¤ì œ vs ì˜ˆìƒ ì¬ê³  |

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ë„êµ¬

### 1. Locust (Python ê¸°ë°˜)

```python
# load_tests/locustfile.py
from locust import HttpUser, task, between
import random

class BlackFridayUser(HttpUser):
    wait_time = between(0.1, 0.5)  # 0.1~0.5ì´ˆ ëŒ€ê¸°

    def on_start(self):
        """ì‚¬ìš©ì ì„¸ì…˜ ì‹œì‘ ì‹œ ë¡œê·¸ì¸"""
        response = self.client.post("/login", json={
            "username": f"user_{random.randint(1, 10000)}",
            "password": "password123"
        })
        if response.status_code == 200:
            self.token = response.json()["access_token"]
            self.client.headers.update({
                "Authorization": f"Bearer {self.token}"
            })

    @task(3)
    def check_inventory(self):
        """ì¬ê³  ì¡°íšŒ (30% ë¹„ì¤‘)"""
        product_id = random.randint(1, 10)
        self.client.get(f"/inventory/{product_id}")

    @task(7)
    def purchase_item(self):
        """êµ¬ë§¤ ì‹œë„ (70% ë¹„ì¤‘)"""
        product_id = random.randint(1, 10)
        quantity = random.randint(1, 3)
        self.client.post(
            f"/purchase/{product_id}",
            json={"quantity": quantity}
        )
```

### 2. ì‹¤í–‰ ëª…ë ¹ì–´

```bash
# Web UI ëª¨ë“œ
uv run locust -f load_tests/locustfile.py \
    --host http://localhost:8000

# Headless ëª¨ë“œ (CI/CDìš©)
uv run locust -f load_tests/locustfile.py \
    --host http://localhost:8000 \
    --headless \
    --users 1000 \
    --spawn-rate 50 \
    --run-time 60s \
    --csv=results/test_$(date +%Y%m%d_%H%M%S)
```

### 3. pytest-asyncio (ë™ì‹œì„± í…ŒìŠ¤íŠ¸)

```python
# tests/test_concurrency.py
import pytest
import asyncio
import aiohttp

@pytest.mark.asyncio
async def test_concurrent_purchases():
    """100ëª…ì´ ë™ì‹œì— 1ê°œì”© êµ¬ë§¤"""

    async def purchase_one(session, user_id):
        headers = {"Authorization": f"Bearer {tokens[user_id]}"}
        async with session.post(
            f"http://localhost:8000/purchase/1",
            json={"quantity": 1},
            headers=headers
        ) as response:
            return response.status

    # 100ëª… ë™ì‹œ ìš”ì²­
    async with aiohttp.ClientSession() as session:
        tasks = [
            purchase_one(session, i)
            for i in range(100)
        ]
        results = await asyncio.gather(*tasks)

    # ê²€ì¦: ì •í™•íˆ 100ê°œ íŒë§¤
    success_count = results.count(200)
    assert success_count == 100
    assert results.count(400) == 0  # ì¬ê³  ë¶€ì¡± ì—†ìŒ
```

---

## ğŸ“ˆ í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### Scenario 1: Baseline Test (ê¸°ì¤€ì„  ì„¤ì •)

```yaml
name: Baseline Performance Test
description: ë‹¨ì¼ ì‚¬ìš©ìë¡œ ì‹œìŠ¤í…œ ê¸°ë³¸ ì„±ëŠ¥ ì¸¡ì •
steps:
  - users: 1
    duration: 60s
    requests:
      - GET /inventory/1: 50%
      - POST /purchase/1: 50%
expected:
  - response_time_p99: < 50ms
  - error_rate: 0%
```

### Scenario 2: Load Test (ë¶€í•˜ í…ŒìŠ¤íŠ¸)

```yaml
name: Black Friday Load Test
description: ì ì§„ì  ë¶€í•˜ ì¦ê°€
steps:
  - users: 100
    duration: 120s
    ramp_up: 30s
  - users: 500
    duration: 120s
    ramp_up: 30s
  - users: 1000
    duration: 300s
    ramp_up: 60s
expected:
  - tps: > 100
  - response_time_p99: < 500ms
  - error_rate: < 1%
```

### Scenario 3: Spike Test (ìŠ¤íŒŒì´í¬ í…ŒìŠ¤íŠ¸)

```yaml
name: Flash Sale Spike Test
description: ê°‘ì‘ìŠ¤ëŸ¬ìš´ íŠ¸ë˜í”½ ê¸‰ì¦
steps:
  - users: 10
    duration: 30s
  - users: 1000  # ê°‘ìê¸° ì¦ê°€
    duration: 60s
    ramp_up: 5s
  - users: 10
    duration: 30s
expected:
  - system_recovery_time: < 10s
  - no_system_crash: true
```

### Scenario 4: Stress Test (í•œê³„ í…ŒìŠ¤íŠ¸)

```yaml
name: System Breaking Point Test
description: ì‹œìŠ¤í…œ í•œê³„ì  íŒŒì•…
steps:
  - start_users: 100
    increment: 100
    increment_interval: 60s
    max_users: 5000
expected:
  - identify_breaking_point: true
  - graceful_degradation: true
```

### Scenario 5: Soak Test (ì¥ì‹œê°„ í…ŒìŠ¤íŠ¸)

```yaml
name: Long Duration Test
description: ë©”ëª¨ë¦¬ ëˆ„ìˆ˜, ì„±ëŠ¥ ì €í•˜ í™•ì¸
steps:
  - users: 500
    duration: 3600s  # 1ì‹œê°„
expected:
  - memory_leak: false
  - performance_degradation: < 10%
  - error_rate_stable: true
```

---

## ğŸ”§ í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì„±

### í•˜ë“œì›¨ì–´ ì‚¬ì–‘

```yaml
Test Server:
  CPU: 8 cores (Intel Xeon)
  RAM: 16GB
  Disk: SSD 100GB
  Network: 1Gbps

Redis Server:
  CPU: 4 cores
  RAM: 8GB (Redis ì „ìš©)
  Persistence: AOF enabled

Load Generator:
  CPU: 4 cores
  RAM: 8GB
  Location: Same network (< 1ms latency)
```

### Docker Compose í…ŒìŠ¤íŠ¸ í™˜ê²½

```yaml
# docker-compose.test.yml
version: '3.8'

services:
  app:
    build: .
    environment:
      - WORKERS=4
      - LOG_LEVEL=WARNING
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 4G

  redis:
    image: redis:7-alpine
    command: redis-server --maxmemory 2gb --maxmemory-policy allkeys-lru
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G

  locust:
    image: locustio/locust
    volumes:
      - ./load_tests:/mnt/locust
    command: -f /mnt/locust/locustfile.py --host http://app:8000
```

---

## ğŸ“‰ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘

### 1. Application Metrics

```python
# app/metrics.py
from prometheus_client import Counter, Histogram, Gauge

# ìš”ì²­ ì¹´ìš´í„°
request_count = Counter(
    'http_requests_total',
    'Total HTTP requests',
    ['method', 'endpoint', 'status']
)

# ì‘ë‹µ ì‹œê°„ íˆìŠ¤í† ê·¸ë¨
request_duration = Histogram(
    'http_request_duration_seconds',
    'HTTP request duration',
    ['method', 'endpoint']
)

# í˜„ì¬ ì¬ê³ 
current_stock = Gauge(
    'inventory_stock_current',
    'Current stock level',
    ['product_id']
)

# ë½ ë©”íŠ¸ë¦­
lock_acquired = Counter('lock_acquired_total', 'Locks acquired')
lock_failed = Counter('lock_failed_total', 'Lock failures')
lock_wait_time = Histogram('lock_wait_seconds', 'Lock wait time')
```

### 2. Redis Metrics

```bash
# Redis ëª¨ë‹ˆí„°ë§ ëª…ë ¹ì–´
redis-cli --stat  # ì‹¤ì‹œê°„ í†µê³„

# ì£¼ìš” ë©”íŠ¸ë¦­
redis-cli INFO stats
# - total_connections_received: ì´ ì—°ê²° ìˆ˜
# - instantaneous_ops_per_sec: ì´ˆë‹¹ ëª…ë ¹ ì²˜ë¦¬
# - rejected_connections: ê±°ë¶€ëœ ì—°ê²°

redis-cli INFO memory
# - used_memory: ì‚¬ìš© ë©”ëª¨ë¦¬
# - mem_fragmentation_ratio: ë©”ëª¨ë¦¬ ë‹¨í¸í™”

# ë½ ê´€ë ¨ ë©”íŠ¸ë¦­
redis-cli --scan --pattern "lock:*" | wc -l  # í™œì„± ë½ ìˆ˜
```

### 3. System Metrics

```bash
# CPU ì‚¬ìš©ë¥ 
top -b -n 1 | grep "Cpu(s)"

# ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
free -h

# ë„¤íŠ¸ì›Œí¬ í†µê³„
netstat -s

# ë””ìŠ¤í¬ I/O
iostat -x 1

# í”„ë¡œì„¸ìŠ¤ë³„ ë¦¬ì†ŒìŠ¤
ps aux | grep python
```

---

## ğŸ“Š ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸

### 1. ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ ê²°ê³¼ í…œí”Œë¦¿

```markdown
## Test Report: [Test Name]
- Date: 2024-01-01
- Version: v1.0
- Duration: 60 seconds
- Users: 1000 concurrent

### Summary
- âœ… TPS: 150 (Target: 100)
- âš ï¸ P99 Response Time: 550ms (Target: 500ms)
- âœ… Error Rate: 0.05% (Target: < 0.1%)
- âœ… Inventory Accuracy: 100%

### Detailed Results
| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| Requests/sec | 150 | 100 | âœ… Pass |
| P50 Latency | 80ms | 100ms | âœ… Pass |
| P95 Latency | 320ms | 400ms | âœ… Pass |
| P99 Latency | 550ms | 500ms | âš ï¸ Warning |

### Bottlenecks Identified
1. Redis lock contention at > 800 users
2. Database write queue buildup
3. Connection pool exhaustion

### Recommendations
1. Increase Redis connection pool size
2. Implement write batching for purchases
3. Add read replicas for inventory checks
```

### 2. ê·¸ë˜í”„ ìƒì„± ìŠ¤í¬ë¦½íŠ¸

```python
# scripts/analyze_results.py
import pandas as pd
import matplotlib.pyplot as plt

def analyze_locust_results(csv_file):
    """Locust ê²°ê³¼ CSV ë¶„ì„ ë° ì‹œê°í™”"""

    # ë°ì´í„° ë¡œë“œ
    stats = pd.read_csv(f"{csv_file}_stats.csv")

    # ì‹œê°„ëŒ€ë³„ TPS ê·¸ë˜í”„
    plt.figure(figsize=(12, 6))

    plt.subplot(2, 2, 1)
    plt.plot(stats['Timestamp'], stats['Requests/s'])
    plt.title('Throughput Over Time')
    plt.xlabel('Time')
    plt.ylabel('Requests/sec')

    # ì‘ë‹µì‹œê°„ ë¶„í¬
    plt.subplot(2, 2, 2)
    plt.hist(stats['95%'], bins=50, alpha=0.7, label='P95')
    plt.hist(stats['99%'], bins=50, alpha=0.7, label='P99')
    plt.title('Response Time Distribution')
    plt.xlabel('Response Time (ms)')
    plt.ylabel('Frequency')
    plt.legend()

    # ì—ëŸ¬ìœ¨ ì¶”ì´
    plt.subplot(2, 2, 3)
    plt.plot(stats['Timestamp'], stats['Failures/s'])
    plt.title('Error Rate Over Time')
    plt.xlabel('Time')
    plt.ylabel('Errors/sec')

    # ë™ì‹œ ì‚¬ìš©ì ìˆ˜
    plt.subplot(2, 2, 4)
    plt.plot(stats['Timestamp'], stats['User Count'])
    plt.title('Concurrent Users')
    plt.xlabel('Time')
    plt.ylabel('Users')

    plt.tight_layout()
    plt.savefig('performance_report.png')
```

---

## ğŸš€ ì„±ëŠ¥ ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

### Application Level

- [ ] Connection pooling êµ¬ì„±
- [ ] ë¹„ë™ê¸° ì²˜ë¦¬ ìµœì í™”
- [ ] ë¶ˆí•„ìš”í•œ ë¡œê¹… ì œê±°
- [ ] JSON serialization ìµœì í™”
- [ ] Prepared statements ì‚¬ìš©

### Redis Level

- [ ] Pipeline/Transaction ì‚¬ìš©
- [ ] Lua script ìµœì í™”
- [ ] ì ì ˆí•œ maxclients ì„¤ì •
- [ ] TCP keepalive ì„¤ì •
- [ ] Persistence ì„¤ì • ì¡°ì •

### Database Level

- [ ] Index ìµœì í™”
- [ ] Query ìµœì í™”
- [ ] Connection pool ì¡°ì •
- [ ] Write batching
- [ ] Read replica êµ¬ì„±

### Infrastructure Level

- [ ] CPU governor ì„±ëŠ¥ ëª¨ë“œ
- [ ] Network buffer í¬ê¸° ì¡°ì •
- [ ] File descriptor limit ì¦ê°€
- [ ] Swap ë¹„í™œì„±í™”
- [ ] THP (Transparent Huge Pages) ë¹„í™œì„±í™”

---

## ğŸ” ë³‘ëª© ì§€ì  ì§„ë‹¨

### 1. APM ë„êµ¬ í™œìš©

```python
# New Relic, DataDog, AppDynamics í†µí•©
from newrelic import agent

@agent.function_trace()
async def purchase_with_lock(product_id: int):
    # ìë™ìœ¼ë¡œ ì„±ëŠ¥ ì¶”ì 
    pass
```

### 2. í”„ë¡œíŒŒì¼ë§

```bash
# cProfile ì‹¤í–‰
python -m cProfile -o profile.stats app/main.py

# ê²°ê³¼ ë¶„ì„
python -c "import pstats; p = pstats.Stats('profile.stats'); p.sort_stats('cumulative').print_stats(20)"
```

### 3. ë³‘ëª© ì§€ì ë³„ ëŒ€ì‘

| ë³‘ëª© ì§€ì  | ì¦ìƒ | í•´ê²° ë°©ë²• |
|-----------|------|-----------|
| CPU | High CPU usage | ì½”ë“œ ìµœì í™”, ìŠ¤ì¼€ì¼ ì•„ì›ƒ |
| Memory | OOM, Swap ì‚¬ìš© | ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ìˆ˜ì •, ìºì‹œ ì •ë¦¬ |
| Network | High latency | Connection pool, Keep-alive |
| Disk I/O | Slow writes | SSD ì‚¬ìš©, ë¹„ë™ê¸° ì“°ê¸° |
| Lock contention | ëŒ€ê¸° ì‹œê°„ ì¦ê°€ | ë½ ì„¸ë¶„í™”, ìƒ¤ë”© |

---

## ğŸ“ í…ŒìŠ¤íŠ¸ ìë™í™”

### GitHub Actions CI/CD

```yaml
# .github/workflows/performance-test.yml
name: Performance Test

on:
  schedule:
    - cron: '0 2 * * *'  # ë§¤ì¼ ìƒˆë²½ 2ì‹œ

jobs:
  performance-test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v2

      - name: Setup environment
        run: |
          docker-compose -f docker-compose.test.yml up -d
          sleep 10

      - name: Run performance test
        run: |
          docker run --rm \
            --network host \
            -v $PWD/load_tests:/mnt/locust \
            locustio/locust \
            -f /mnt/locust/locustfile.py \
            --host http://localhost:8000 \
            --headless \
            --users 100 \
            --spawn-rate 10 \
            --run-time 60s \
            --csv=results/test

      - name: Analyze results
        run: python scripts/analyze_results.py results/test

      - name: Upload artifacts
        uses: actions/upload-artifact@v2
        with:
          name: performance-results
          path: results/
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Locust Documentation](https://docs.locust.io/)
- [Redis Benchmarking](https://redis.io/docs/management/optimization/benchmarks/)
- [FastAPI Performance Tips](https://fastapi.tiangolo.com/deployment/concepts/)
- [High Performance Browser Networking](https://hpbn.co/)